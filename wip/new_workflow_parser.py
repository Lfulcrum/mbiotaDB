# -*- coding: utf-8 -*-
"""
Created on Tue May 26 16:09:53 2020

@author: William
"""

# Standard library imports
import json

# Third-party imports
import networkx as nx

# Local application imports
from model import Processing, Workflow


# TODO: In the future, perhaps we should clean the Qiita processing data
# to avoid non-uniform interface here.
# For Qiita data, we must use parent_keys: ['input_data', 'demultiplexed sequences']
# unless we first clean the processing data to make it more uniform.
def parse_processing_parents(processings, parent_keys):
    """Return a dictionary relating each processing identifier to its parent.

    Parameters
    ----------
    processings : dict
        A dictionary of processing data, whose keys are processing identifiers
        and values are dictionaries containing corresponding processing data.
        This sort of dictionary is generated by reading the JSON file containing
        processing/artifact metadata derived from the processing network/tree on
        Qiita.
    parent_keys : ordered iterable of str
        An ordered collection of strings that are keys that will be
        sequentially used to find parent processing identifiers in the
        processing data of the `processings` argument.

    Returns
    -------
    dict
        Dictionary whose keys are processing identifiers and values are the
        identifiers of a parent processing.
    """
    processing_parents = {}
    for proc_id, proc_data in processings.items():
        for key in parent_keys:
            try:
                parent_id = proc_data[key]
            except KeyError:
                # Processings can also have no parents, in which case the for
                # loop will simply exhaust all keys.
                pass
            else:
                processing_parents[proc_id] = parent_id
                break
    return processing_parents


def parse_processings(processings):
    """Parse processing data into Processing objects.

    Parameters
    ----------
    processings : dict
        A dictionary of processing data, whose keys are processing identifiers
        and values are dictionaries containing corresponding processing data.
        This sort of dictionary is generated by reading the JSON file containing
        processing/artifact metadata derived from the processing network/tree on
        Qiita.
    prep_id : str
        The identifier of the preparation to which processings relates.

    Returns
    -------
    dict
        Dictionary whose keys are processing identifiers and values are the
        corresponding Processing objects.
    """
    processing_dict = {}
    for proc_id, proc_data in processings.items():
        json_proc_data = json.dumps(proc_data,
                                    separators=[',', ':'],
                                    allow_nan=False)
        processing = Processing(parameter_values=json_proc_data)
        processing_dict[proc_id] = processing
    return processing_dict


def form_processing_relationships(processings, processing_parents):
    """Establish parent relationship between Processing objects.

    Parameters
    ----------
    processings : dict
        Dictionary whose keys are processing identifiers and values are the
        corresponding Processing objects.
    processing_parents : dict
        Dictionary whose keys are processing identifiers and values are the
        identifiers of a parent processing.
    """
    for proc_id, parent_id in processing_parents.items():
        processings[proc_id].parent = processings[parent_id]


def parse_prep_workflows(processing_parents, processings):
    tree = nx.DiGraph()
    tree.add_edges_from(processing_parents.items())
    terminals = [node for node, degree in tree.in_degree if degree == 0]
    roots = [node for node, degree in tree.out_degree if degree == 0]
    paths = []
    prep_workflows = {}
    # The following still won't work if we have two disconnected trees
    # and hence more than one root because the terminals will be a list of
    # terminals for both trees and therefore a path won't exist for some
    # terminals to a root.
    for root in roots:
        for terminal in terminals:
            # Assume one path from terminal to root
            path = next(nx.all_simple_paths(tree, terminal, root))
            paths.append(path)
            workflow_processings = []
            for node in path:
                workflow_processings.append(processings[node])
            # Index workflows by the terminal processing id
            workflow = Workflow(processings=workflow_processings)
            prep_workflows[terminal] = workflow
    return prep_workflows


def parse_workflows(processing_file, index_by='terminal_proc'):
    workflow_views = {}
    prep_workflows_view = {}
    proc_workflows_view = {}
    with open(processing_file) as file:
        json_str = file.read()
        processing_data = json.loads(json_str)
    for preps in processing_data:
        for prep_id, processings in preps.items():
            processing_parents = parse_processing_parents(processings)
            processing_dict = parse_processings(processings, prep_id)
            prep_workflows = parse_prep_workflows(processing_parents,
                                                  processing_dict)
            prep_workflows_view[prep_id] = list(prep_workflows.values())
            for terminal_proc, workflow in prep_workflows.items():
                proc_workflows_view[terminal_proc] = workflow
    workflow_views['terminal_proc'] = proc_workflows_view
    workflow_views['prep'] = prep_workflows_view
    try:
        index_by + ''
        return workflow_views[index_by]
    except TypeError:
        return [workflow_views[index] for index in index_by]
